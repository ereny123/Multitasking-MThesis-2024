{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ereny123/Multitasking-MThesis-2024/blob/main/Pytorch_NET_Multitasking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vEze7K4r8bU1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Eo6cAkSZm1pN"
      },
      "outputs": [],
      "source": [
        "#create a model class\n",
        "class Model(nn.Module):\n",
        "  #Input (Tasks) random array of 9 units\n",
        "  def __init__(self, in_tasks=9, in_stim=3, hidden= 100, output=9, bias_weight=-2):\n",
        "    super().__init__()\n",
        "\n",
        "    #Set Parameters\n",
        "    self.bias_weight = bias_weight   # default bias weight\n",
        "\n",
        "    self.task_hidden=nn.Linear(in_tasks, hidden)    #input layer(tasks) --> hidden layer\n",
        "    self.stim_hidden=nn.Linear(in_stim, hidden)    #input layer(stimuls) --> hidden layer\n",
        "    self.hidden_out=nn.Linear(hidden, output)       #hidden layer --> output layer\n",
        "\n",
        "    self.task_hidden.weight=nn.Parameter(torch.FloatTensor(hidden, in_tasks).uniform_(-0.1, 0.1))   #input(tasks)-->hidden  weight\n",
        "    self.stim_hidden.weight=nn.Parameter(torch.FloatTensor(hidden, in_stim).uniform_(-0.1, 0.1))    #input(stimulus) -->hidden weight\n",
        "    self.hidden_out.weight=nn.Parameter(torch.FloatTensor(output, hidden).uniform_(-0.1, 0.1))      #hidden-->output  weight\n",
        "\n",
        "    self.task_hidden.bias=nn.Parameter(torch.ones(hidden) * bias_weight)                         #hidden layer bias\n",
        "    self.hidden_out.bias=nn.Parameter(torch.ones(output) * bias_weight)                    #output layer bias\n",
        "\n",
        "  def forward(self, taskData, stimulusData):\n",
        "    #h_act=torch.matmul(self.fc1.weight, taskData)+ self.fc1.bias   #hidden layer activation\n",
        "    #h_act= F.tanh(self.h_act)\n",
        "    #out_act=torch.matmul(self.fc2.weight, h_act) + self.fc2.bias    #output layer activation\n",
        "\n",
        "    h_act=torch.sigmoid(self.task_hidden(taskData)+self.stim_hidden(stimulusData))\n",
        "    out_act= self.hidden_out(h_act)\n",
        "\n",
        "    return h_act, out_act\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07chQ-FGKb-D",
        "outputId": "f13aebc0-ce24-45cc-c1d1-99dcaac877de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (task_hidden): Linear(in_features=9, out_features=100, bias=True)\n",
            "  (stim_hidden): Linear(in_features=3, out_features=100, bias=True)\n",
            "  (hidden_out): Linear(in_features=100, out_features=9, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#Pick a manual seed for randomization for the input values\n",
        "#torch.manual_seed(1729)\n",
        "#tasks= torch.rand(1,9)\n",
        "#tasks\n",
        "\n",
        "\n",
        "#create an instance for Model\n",
        "model = Model()\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "rML6CIvDCqW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1154331-b2e6-4ba8-d6d8-e8965dd74c74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "tensor([0., 1., 1.])\n"
          ]
        }
      ],
      "source": [
        "X = numpy.array([1, 2, 3 , 4, 5, 6, 7, 8, 9])\n",
        "taskData = torch.from_numpy(X)\n",
        "taskData=taskData.to(torch.float32)\n",
        "\n",
        "Z=numpy.array([0,1,1])\n",
        "stimulusData= torch.from_numpy(Z)\n",
        "stimulusData=stimulusData.to(torch.float32)\n",
        "\n",
        "print(taskData)\n",
        "print(stimulusData)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(taskData, stimulusData)"
      ],
      "metadata": {
        "id": "XeNRNLqDU36X",
        "outputId": "0fd05791-82d6-4979-8a47-69fb0b3397b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.2013, 0.0706, 0.1204, 0.2274, 0.3518, 0.1996, 0.1138, 0.0780, 0.0681,\n",
              "         0.1455, 0.1853, 0.5240, 0.0156, 0.1727, 0.0402, 0.3577, 0.3332, 0.0785,\n",
              "         0.1337, 0.2777, 0.0692, 0.0727, 0.1810, 0.1608, 0.1547, 0.1369, 0.0488,\n",
              "         0.0837, 0.0316, 0.2525, 0.1218, 0.0714, 0.0471, 0.0968, 0.1973, 0.0692,\n",
              "         0.2253, 0.2347, 0.1048, 0.0757, 0.0516, 0.1154, 0.1139, 0.4133, 0.1342,\n",
              "         0.0218, 0.0297, 0.0338, 0.0708, 0.2750, 0.0310, 0.0421, 0.1989, 0.2773,\n",
              "         0.0527, 0.1423, 0.1070, 0.2343, 0.5497, 0.0381, 0.3139, 0.4839, 0.1115,\n",
              "         0.0768, 0.0496, 0.0420, 0.1768, 0.1300, 0.2744, 0.1465, 0.0958, 0.0300,\n",
              "         0.2415, 0.1761, 0.1848, 0.1257, 0.0327, 0.2192, 0.4601, 0.2853, 0.1510,\n",
              "         0.0844, 0.1815, 0.3252, 0.0430, 0.0247, 0.0521, 0.2898, 0.0303, 0.0178,\n",
              "         0.0675, 0.1282, 0.1948, 0.1016, 0.0772, 0.1315, 0.4355, 0.3498, 0.2851,\n",
              "         0.0834], grad_fn=<SigmoidBackward0>),\n",
              " tensor([-1.9042, -1.9486, -2.2325, -1.9064, -2.0178, -1.9636, -1.9623, -2.0245,\n",
              "         -2.1197], grad_fn=<ViewBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}